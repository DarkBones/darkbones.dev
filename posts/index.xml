<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on DarkBones</title><link>https://darkbones.dev/posts/</link><description>Recent content in Posts on DarkBones</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 25 Feb 2025 16:55:55 +0100</lastBuildDate><atom:link href="https://darkbones.dev/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Beyond Training Data: How RAG Lets LLMs Retrieve, Not Guess</title><link>https://darkbones.dev/posts/explaining-rag/</link><pubDate>Sun, 23 Feb 2025 12:34:51 +0100</pubDate><guid>https://darkbones.dev/posts/explaining-rag/</guid><description>&lt;p>&lt;img src="cover-image.png" alt="An AI, depicted as a lone figure, stands in a vast, futuristic library representing a vector knowledge base. Towering bookshelves stretch endlessly, filled with knowledge, while books float dynamically in the air - symbolizing retrieved context. A glowing blue light from above signifies the AI&amp;rsquo;s reasoning process, illuminating the fusion of retrieval and generation in the world of RAG (Retrieval-Augmented Generation).">&lt;/p>
&lt;p>&lt;strong>Large Language Models (LLMs) like GPT-4 don’t actually ‘know’ anything, they predict words based on old training data. Retrieval-Augmented Generation (RAG) changes that by letting AI pull in fresh, real-world knowledge before answering.&lt;/strong>&lt;/p></description><content type="html"><![CDATA[<p><img src="cover-image.png" alt="An AI, depicted as a lone figure, stands in a vast, futuristic library representing a vector knowledge base. Towering bookshelves stretch endlessly, filled with knowledge, while books float dynamically in the air - symbolizing retrieved context. A glowing blue light from above signifies the AI&rsquo;s reasoning process, illuminating the fusion of retrieval and generation in the world of RAG (Retrieval-Augmented Generation)."></p>
<p><strong>Large Language Models (LLMs) like GPT-4 don’t actually ‘know’ anything, they predict words based on old training data. Retrieval-Augmented Generation (RAG) changes that by letting AI pull in fresh, real-world knowledge before answering.</strong></p>
<p><strong>RAG enhances LLMs by enabling them to retrieve relevant information from external sources before generating a response. Because LLMs rely on static training data and don’t update automatically, RAG gives them access to fresh, domain-specific, or private knowledge, without the need for costly retraining.</strong></p>
<p><strong>Let’s explore how RAG works, why it is useful, and how it differs from traditional LLM prompting.</strong></p>
<h2 id="what-is-retrieval-augmented-generation-rag-in-ai">What is Retrieval-Augmented Generation (RAG) in AI?</h2>
<p>Retrieval-Augmented Generation (RAG) helps AI models retrieve external information before generating a response. But how exactly does this process work, and why is it important?</p>
<p>Large Language Models excel at many tasks. They can code, draft emails, hallucinate ingredients for the perfect sandwich, and even write articles, although I still prefer doing that myself. However, they have a <em>major limitation</em>. They lack real-time knowledge. Because training LLMs is a time-consuming process, they do not <em>&ldquo;know&rdquo;</em> about recent events. If you ask one about last week, it will either display a disclaimer, provide an outdated answer, or generate something completely inaccurate.</p>
<blockquote>
<p><strong>&ldquo;Some LLMs overcome their biggest limitation of stale training data by retrieving up-to-date information before responding.&rdquo;</strong></p></blockquote>
<p>RAG fetches relevant information before generating an answer, making AI responses more accurate and reducing hallucinations.</p>
<h2 id="rag-explained-in-simple-terms">RAG Explained in Simple Terms</h2>
<p>But how does <em>RAG</em> <strong>actually</strong> work? Instead of looking it up ourselves, let’s ask our favorite LLM:
<img src="1-rag-is-a-piece-of-cloth.png" alt="A two-panel comic featuring a stick figure and an AI assistant labeled &ldquo;LLM.&rdquo; In the first panel, the person asks, &ldquo;Hey LLM, tell me about RAG.&rdquo; In the second panel, the AI responds, &ldquo;Certainly, a rag is a waste piece of cloth,&rdquo; misunderstanding the request. The person sighs in frustration."></p>
<p>This is not quite what we were hoping for. No problem, we can ask <em>Bob</em> instead.
<img src="2-bob-rag.png" alt="A four-panel comic of a red stick figure asking Bob about RAG. Bob visits a librarian, who directs him to a book. Bob reads &ldquo;RAG stands for Retrieval-Augmented Generation.&rdquo; He returns and explains, &ldquo;RAG is short for Retrieval-Augmented Generation and helps provide context to LLMs.&rdquo;"></p>
<p>Surprisingly, Bob did not know the answer either, but he was able to retrieve it. Here is what happened:</p>
<ol>
<li>We asked Bob about <em>RAG</em>.</li>
<li>Bob went to the <em>library</em> and asked the <em>librarian</em> for information.</li>
<li>The <em>librarian</em> pointed him to the right aisle.</li>
<li>Bob <strong>retrieved</strong> the information.</li>
<li>Bob <strong>augmented</strong> his understanding by consuming the information before <strong>generating</strong> an answer.</li>
<li>Now Bob sounds like an expert. Thanks, Bob.</li>
</ol>
<p>This breakdown reveals that Bob is effectively functioning as a <em>RAG agent</em>.</p>
<p>With that insight, let’s explore exactly how a RAG agent operates.</p>
<h2 id="rag---simplified">RAG - Simplified</h2>
<p>Let&rsquo;s transform our interaction with Bob into an actual RAG system:</p>
<ul>
<li>Bob represents the <strong>RAG system</strong>.</li>
<li>The librarian acts as an <strong>embedder</strong>.</li>
<li>The library functions as a <strong>vector database</strong>.</li>
</ul>
<p><img src="4-rag-system.png" alt="A six-panel comic explaining RAG. A person asks an AI system about RAG. The AI sends it to an embedder, which converts it into a vector. The AI system retrieves relevant data from a vector database. The AI system then augments the user&rsquo;s query with the retrieved context before sending it to an LLM, which correctly answers, &ldquo;RAG stands for Retrieval-Augmented Generation and is a technique to retrieve data from a knowledge base.&rdquo;"></p>
<blockquote>
<p><strong>&ldquo;Rather than prompting an LLM directly, a <em>RAG system</em> acts as a knowledge bridge: retrieving, augmenting, and then generating responses.&rdquo;</strong></p></blockquote>
<h3 id="vectorizing-the-input">Vectorizing the Input</h3>
<p>The <em>RAG system</em> then forwards the prompt to the <em>embedder</em>, which converts it into a <em>vector</em>. This <em>vector</em> is a numeric representation of the prompt. The idea is that information with similar meaning will have similar vector representations.</p>
<blockquote>
<p><strong>&ldquo;Vectors unlock relevance. This <em>vector</em> allows the system to retrieve the most meaningful information from the <em>vector database</em>.&rdquo;</strong></p></blockquote>
<p>When the vector representation of the user&rsquo;s prompt is sent to the database, it retrieves the <em>most relevant matches</em>.</p>
<p>The <em>RAG system</em> then enhances the user&rsquo;s prompt by including the retrieved information:</p>
<pre tabindex="0"><code>&lt;context&gt;
the information returned from the database
&lt;/context&gt;
&lt;user-prompt&gt;
the user&#39;s original prompt
&lt;/user-prompt&gt;
</code></pre><p>That is the entire process. <em>Retrieve</em>, <em>Augment</em>, and <em>Generate</em>. <strong>RAG</strong>.</p>
<h3 id="adding-to-the-knowledge-base">Adding to the Knowledge Base</h3>
<p>However, the system cannot retrieve information that has not been added to the database. How do we store new data? The process is straightforward. Instead of using the vector to find relevant information, the system stores the data along with its <em>vector representation</em>.</p>
<p><img src="3-rag-injest.png" alt="A three-panel comic explaining how RAG stores knowledge. A person gives a document about RAG to an AI system. The AI processes it, converting text into a vector representation with help from an embedder. The AI then stores the vectorized information in a vector database, confirming with &ldquo;Successfully inserted 1 row.&rdquo;"></p>
<p>If you were only interested in the big picture, congratulations. You now understand the core concept. However, if you&rsquo;re a fellow neckbeard, let&rsquo;s talk a bit more about vectors and embedders.</p>
<h2 id="what-is-a-vector">What is a Vector?</h2>
<p>In simple terms, a vector is a set of coordinates that describe how to move from A to B. Look at this graph:</p>
<p><img src="5-look-at-this-graph.jpg" alt="A digitally edited image of the &ldquo;Photograph&rdquo; meme from Nickelback&rsquo;s music video. The picture frame now contains a graph with labeled vectors on a black background, showing coordinate points and directional lines."></p>
<p>This graph has two dimensions. Each point, <strong>A</strong>, <strong>B</strong>, <strong>C</strong>, and <strong>D</strong>, can be described using a two-number coordinate system. The first number tells us how far to move to the right from the origin (0), while the second number tells us how far to move up. To reach <strong>A</strong>, the vector is <code>[3, 7]</code>. To reach <strong>D</strong>, the vector is <code>[3, 0]</code>.</p>
<h3 id="dimensionality-of-vectors">Dimensionality of Vectors</h3>
<p>The same principle applies in <em>three dimensions</em>. To move from your desk to the coffee machine, you must travel a certain distance along the <code>x</code>, <code>y</code>, and <code>z</code> axes, forming a <em>three-digit</em> coordinate system.</p>
<p><img src="6-3d-vector.png" alt="A 3D coordinate graph with a labeled point A(6,5,9). A red vector extends from the origin (0,0,0) to the point, illustrating a position in three-dimensional space."></p>
<blockquote>
<p><strong>&ldquo;Humans struggle to visualize beyond three dimensions. Computers thrive in multi-dimensional spaces.&rdquo;</strong></p></blockquote>
<p>The math remains the same. Four dimensions? That requires a <em>four-digit</em> coordinate system. One hundred dimensions? That requires a <em>100-digit</em> coordinate system.</p>
<p><img src="this-is-fine.png" alt="A two-panel meme comparing how humans and computers perceive high-dimensional space. The left side, labeled &ldquo;HUMANS,&rdquo; shows a chaotic scribble. The right side, labeled &ldquo;COMPUTERS,&rdquo; features the &ldquo;This is fine&rdquo; meme with a dog sitting in a room but without the fire, implying that computers handle complexity with ease."></p>
<blockquote>
<p><strong>&ldquo;The embedder I use operates in a mind-bending, 768-dimensional coordinate system, far beyond human perception.&rdquo;</strong></p></blockquote>
<p>When you have finished trying to visualize that, we can return to simpler, easy-to-draw, two-dimensional graphs.</p>
<h2 id="how-vector-embeddings-help-llms-retrieve-data">How Vector Embeddings Help LLMs Retrieve Data</h2>
<p>Vectors by themselves are simply <em>n-dimensional coordinates</em> that represent points in <em>n-dimensional space</em>.</p>
<blockquote>
<p><strong>&ldquo;Vectors aren’t just numbers, they encode meaning. Their true power lies in the information they represent.&rdquo;</strong></p></blockquote>
<p>In the same way, vectors are coordinates not to places, but to information. A specialized LLM, an <em>embedder</em>, is trained on a large corpus of text to figure out similarities and to place these pieces of information somewhere in <em>n-dimensional space</em> such that similar topics tend to be grouped together.</p>
<p>Like, when you go to a social event, you&rsquo;re likely to stick with your friends, colleagues, or at least a group of like-minded people.</p>
<h4 id="grouping-similar-concepts-together">Grouping Similar Concepts Together</h4>
<p><img src="7-word2vec.png" alt="A 2D graph visualizing word embeddings. Words are grouped based on meaning: animals (&ldquo;dog,&rdquo; &ldquo;cat,&rdquo; &ldquo;horse&rdquo;), emotions (&ldquo;happy,&rdquo; &ldquo;sad,&rdquo; &ldquo;excited&rdquo;), relationships (&ldquo;friend,&rdquo; &ldquo;spouse&rdquo;), insects (&ldquo;fly,&rdquo; &ldquo;bee&rdquo;), buildings (&ldquo;house,&rdquo; &ldquo;office&rdquo;), and waste-related terms (&ldquo;garbage,&rdquo; &ldquo;trash&rdquo;). The x-axis and y-axis represent abstract dimensions in vector space."></p>
<p>This graph shows how words that are similar in meaning tend to get grouped together in this n-dimensional space. Modern embedders (like <strong>BERT</strong>) don&rsquo;t use single-word embeddings anymore, but generate <em>contextual embeddings</em>.</p>
<p>The ability to group similar concepts in vector space makes embeddings powerful. However, early embedding models like <em>Word2Vec</em> had a <em>significant limitation</em> that modern models have addressed.</p>
<h4 id="quick-tech-tangent">Quick Tech Tangent</h4>
<p>If you&rsquo;ve been working on AI systems for as long as I have, you might be familiar with <strong>Word2Vec</strong>. While groundbreaking when it came out in 2013, it has a major flaw: it assigns a <strong>single vector</strong> to each word, no matter the context.</p>
<p>Take the word <em>&ldquo;bat&rdquo;</em>.</p>
<ul>
<li>Are we talking about the <strong>flying mammal</strong>? Then it should be near <em>&ldquo;mammal&rdquo;</em>, <em>&ldquo;cave&rdquo;</em>, and <em>&ldquo;nocturnal&rdquo;</em>.</li>
<li>Or do we mean a <strong>baseball bat</strong>? Then it belongs near <em>&ldquo;ball&rdquo;</em>, <em>&ldquo;pitch&rdquo;</em>, and <em>&ldquo;base&rdquo;</em> (but what <em>base</em>? Military?)</li>
<li>And what if we&rsquo;re in the world of <strong>fiction</strong>? Then <em>&ldquo;bat&rdquo;</em> relates to <em>&ldquo;vampire&rdquo;</em> and <em>&ldquo;transformation&rdquo;</em>.</li>
</ul>
<p><strong>Word2Vec</strong> can&rsquo;t tell the difference. It picks one and sticks with it.</p>
<p>One thing I find particularly fascinating with Word2Vec is that, since words are now represented by numbers, you can actually do arithmetic on them.</p>
<p>You can make equations like</p>
<blockquote>
<p><strong>&quot;<code>king - man + woman = queen</code> - a legendary example of how AI models map relationships in vector space.&quot;</strong></p></blockquote>
<p>It&rsquo;s wild, but it works (most of the time).</p>
<p><strong>Tangent over.</strong></p>
<h3 id="how-are-vectors-used">How are Vectors Used?</h3>
<p>Now that we understand vectors, the next step is straightforward. We embed the information we want the LLM to access, and when we ask a question about that information, <strong>the question itself should be close to the relevant content in vector space</strong>. The vector database retrieves the <code>n</code> most relevant pieces of content, where <code>n</code> is a configurable number.</p>
<p><em>It also returns the <em>cosine similarity</em> score for each result, indicating how closely the retrieved content matches the query.</em></p>
<h4 id="cosine-similarity">Cosine Similarity</h4>
<blockquote>
<p><strong>&ldquo;Cosine similarity doesn’t just compare numbers, it measures <em>meaning</em> by calculating the angle between two vectors.&rdquo;</strong></p></blockquote>
<p>A smaller angle indicates greater similarity, meaning the retrieved data is more relevant to the prompt.</p>
<p><img src="8-cosine-similarity.png" alt="A diagram explaining cosine similarity. The left graph, labeled &ldquo;SIMILAR,&rdquo; shows two vectors (A and B) with a small angle between them, indicating high similarity. The right graph, labeled &ldquo;UNRELATED,&rdquo; shows vectors A and B with a large angle, indicating low similarity. Cosine similarity measures the angle between vectors to determine relatedness."></p>
<p>In our example, <em>A</em> and <em>B</em> represent the phrases <em>&ldquo;RAG stands for Retrieval Augmented Generation&rdquo;</em> and <em>&ldquo;Hey LLM, tell me about RAG&rdquo;</em>. Since they are closely related, their vectors are similar. If we instead ask <em>&ldquo;Describe an Eclipse&rdquo;</em>, its vector will be far from the others, making it unrelated. However, if <em>&ldquo;RAG stands for Retrieval Augmented Generation&rdquo;</em> is the only entry in the database, <strong>it will still be retrieved</strong>, even if it is not relevant to the query.</p>
<h2 id="limitations-of-rag">Limitations of RAG</h2>
<p>Typically, we do not store and retrieve entire documents in the vector database. If we did, a single large document could easily exceed the context window of the LLM. If the system is configured to return the ten most relevant pieces of information, and each of them is the size of a full article, your computer quickly turns into a space heater. To prevent this, we split the information into chunks of a predefined size, such as <code>1000</code> characters, and we try to keep the sentences and paragraphs intact.</p>
<p>However, splitting information into chunks introduces a new problem. Just as <em>Word2Vec</em> struggles to determine meaning from a single word, RAG often fails to understand the full context of a single chunk, especially when that chunk is extracted from the middle of a document.</p>
<p><img src="9-over-rag.png" alt="A six-panel comic showing a RAG system misunderstanding a query. A person asks an AI about RAG. The system converts the query into a vector, retrieves context from a vector database, and augments the prompt. The AI incorrectly retrieves information about ragtime music instead of Retrieval-Augmented Generation. The final panel shows the person sighing in frustration."></p>
<p>Here is a problem I encountered recently. I keep a detailed work diary where I document all my professional achievements. It is extremely useful during performance reviews. However, when I ask my RAG system what I achieved at my current company, it confidently includes accomplishments from my previous jobs. Because I write this diary in the first person and also include information from other sources written in the first person, the system cannot distinguish between them. As a result, it starts attributing achievements to me that I had nothing to do with. That is how I realized something was wrong. My system was suddenly telling me about all the interesting things I supposedly did away from the computer, which is impossible since I never leave my desk.</p>
<h2 id="conclusion">Conclusion</h2>
<p>RAG makes LLMs more useful by letting them retrieve information they wouldn’t otherwise have access to. But it’s not magic. It comes with its own challenges, from handling context properly to avoiding irrelevant results.</p>
<p>But as I learned firsthand, fetching information isn’t the same as understanding it. That’s why making RAG systems <strong>context-aware</strong> is the next big challenge, one I’ll tackle in my next article.</p>
]]></content></item><item><title>One Foot in the Unknown</title><link>https://darkbones.dev/posts/one-foot-in-the-unknown/</link><pubDate>Sat, 25 Jan 2025 07:05:51 +0100</pubDate><guid>https://darkbones.dev/posts/one-foot-in-the-unknown/</guid><description>&lt;p>&lt;strong>Maybe it&amp;rsquo;s because I&amp;rsquo;m self-taught and didn&amp;rsquo;t start coding professionally until eight years into my now 13-year journey and I never truly got over feeling like I&amp;rsquo;m &amp;ldquo;not good enough yet to get paid for writing code&amp;rdquo;. Perhaps it&amp;rsquo;s pure passion—or even a touch of masochism. Whatever the reason, I embrace a little chaos in my life.&lt;/strong>&lt;/p>
&lt;p>&lt;strong>No matter how you got here—whether with a CS degree, learning everything on YouTube, attending a bootcamp, or, like me, tinkering on personal projects as if your life depended on it—we all start at the same place: Knowing. Absolutely. Nothing.&lt;/strong>&lt;/p></description><content type="html"><![CDATA[<p><strong>Maybe it&rsquo;s because I&rsquo;m self-taught and didn&rsquo;t start coding professionally until eight years into my now 13-year journey and I never truly got over feeling like I&rsquo;m &ldquo;not good enough yet to get paid for writing code&rdquo;. Perhaps it&rsquo;s pure passion—or even a touch of masochism. Whatever the reason, I embrace a little chaos in my life.</strong></p>
<p><strong>No matter how you got here—whether with a CS degree, learning everything on YouTube, attending a bootcamp, or, like me, tinkering on personal projects as if your life depended on it—we all start at the same place: Knowing. Absolutely. Nothing.</strong></p>
<h2 id="phase-0-knowing-nothing">Phase 0: Knowing Nothing</h2>
<p><img src="i_understand_nothing.png" alt="I Understand Nothing"></p>
<p>This phase is as uncomfortable as it is frustrating. One moment, you&rsquo;re on the verge of giving up; the next, you&rsquo;re desperately waiting for that breakthrough when everything finally clicks. Sometimes, you even experience both at once.</p>
<p>The good news is that you don&rsquo;t have to stay in that place forever. The better news is that you can.</p>
<h2 id="phase-1-knowing-something">Phase 1: Knowing &ldquo;Something&rdquo;</h2>
<p><img src="patrick_building.jpg" alt="Knowing Something"></p>
<p>At first, you learn to do something very basic—like writing a program that prints &ldquo;Hello World!&rdquo; to a console. It&rsquo;s a small win, but it&rsquo;s your first taste of what coding can do.</p>
<p>Then, sooner or later, you get an opportunity to put that simple skill to work. Maybe it&rsquo;s a task from your boss, a class assignment, or a requirement in your personal project: printing a line of text to a console. When you get to do that task, your heart leaps with joy. You create a new branch, implement the solution, push it to the repo, and suddenly, everyone can see that little victory and you only turned to Google twice. In that moment, you feel like a real engineer.</p>
<p>I remember feeling like I was on top of the world—at the summit of mount stupid—after learning about <code>if</code> statements. I thought, &ldquo;Programming is just about writing a bunch of <code>if</code> statements to decide whether to do <code>x</code> or <code>y</code>.&rdquo;</p>
<p>But, alas, not every task is as simple as printing a line of text or toggling between <code>x</code> and <code>y</code>.</p>
<h2 id="phase-2-the-perceived-valley-of-despair">Phase 2: The Perceived Valley of Despair</h2>
<p><img src="valley_of_dispair.png" alt="The Valley of Dispair"></p>
<p>Eventually, all who reach the summit of mount stupid must take that inevitable slide down into the valley of despair.</p>
<p>As you tackle more tasks and get better at suppressing the thoughts of giving up, you also discover more layers to the craft. You become partly capable of handling your job or project, yet with every new concept mastered, five more emerge that you <strong>previously</strong> didn&rsquo;t know existed. Upon realizing each of those five things come with their own five things you <strong>currently</strong> don&rsquo;t know the existence of, the thoughts of quitting might grow a little stronger.</p>
<blockquote>
<p>Turns out, a good application is more than a bunch of <code>if</code> statements. Who knew?</p></blockquote>
<p>Every question you ask only seems to spawn more questions. If you&rsquo;re fortunate enough to have a mentor during this phase, you might worry that you&rsquo;re asking too much—fearing you&rsquo;re becoming a burden. And if you&rsquo;re lucky enough to have a good mentor, rest assured, they&rsquo;ve been there too.</p>
<p>It might seem similar to Phase 1, but don&rsquo;t be fooled. This is a whole different beast. Here, you stand with one foot firmly in the chaos of the unknown and the other planted in the comfort of the familiar.</p>
<blockquote>
<p>I know how to write this <code>if</code> statement. And I know how to write a class. But where do I put it? And how do I import it in the other class? And why is my PR rejected with a comment about &rsquo;early returns&rsquo;? And what is an &rsquo;early return&rsquo;? Why do we care about &lsquo;performance&rsquo; so much? It seems fast enough when I run it on my machine&hellip;</p></blockquote>
<h2 id="phase-3-knowing-almost-all-the-things">Phase 3: Knowing Almost All The Things</h2>
<p><img src="bateman.gif" alt="Bateman Walking"></p>
<p>While you’re busy nurturing the foot that’s still in chaos, you might not notice that the area of the familiar is quietly expanding beneath the other. And before you know it, you’re firmly planted in comfort. Welcome to being: &ldquo;A pretty good engineer&rdquo;. You might feel a sense of pride—after all, new tasks no longer fill you with dread because you believe you can handle almost anything the job throws at you.</p>
<p>Sure, you’ll still occasionally be stumped by something new or confusing. But hey, who isn’t?</p>
<blockquote>
<p>Infrastructure is just messy and confusing. Fortunately, we have an infrastructure guy on the team so I never have to worry about setting up Helm charts or poking around in AWS. That&rsquo;s what infrastructure guy™ is for!</p></blockquote>
<p>A sense of peace—one you never realized you never wanted—begins to settle in.</p>
<h2 id="phase-4-knowing-more-than-you-need">Phase 4: Knowing More Than You Need</h2>
<p><img src="knowing_things.jpg" alt="Knowing Things"></p>
<p>Of course, production goes down on the same day that infrastructure guy™ starts his 4-week PTO. &ldquo;Okay, no need to panic,&rdquo; you tell yourself. &ldquo;What did he say during standup the other day? Something about a Kubernetes cluster? I&rsquo;ll take a look.&rdquo;</p>
<p>Great, our sales department has an exciting lead for a big Swiss customer! Wait, what&rsquo;s that? They&rsquo;re required by law to have all their data in Switzerland? But our database is&hellip; in the Cloud? Unless that Cloud is permanently hanging over Zurich, we need to either move our data to Switzerland or set up a separate database there and configure the app to somehow use this other database. Where&rsquo;s infrastructure guy™? Oh right, that was two jobs ago.</p>
<p>Even though you no longer see yourself as being in a &ldquo;learning phase,&rdquo; knowledge continues to accumulate through adversity. You’ve moved from &ldquo;knowing enough to handle your daily tasks&rdquo; to knowing way more than that.</p>
<blockquote>
<p>I&rsquo;m <strong>still</strong> required to learn things? This is BS! I should be cruising, adding years of experience, salary bumps, and fancy titles!</p></blockquote>
<p>That creeping sense of peace eventually turns to dread. Did I lose my passion for tech? Did I trade dissociating at my desk in a call center for dissociating at my desk in a tech firm? Is this really what I worked so dang hard for? What am I going to do for the next 30 years of my life? Is it CRUD operations forever?</p>
<h2 id="deceived-by-comfort">Deceived by Comfort</h2>
<p><img src="tech_is_big.png" alt="Tech Is Big"></p>
<p>Years ago, while mentoring a small team of junior developers, I began to envy how much they were still learning. I found myself wishing I could go back to that exhilarating “Phase 2”—when you’re in the zone, challenged enough to notice improvement from one week to the next.</p>
<p>I thought, if mentoring juniors is the final destination, I might as well get really good at it. So I turned to YouTube for inspiration and ended up finding tech influencers like <a href="https://www.youtube.com/@ThePrimeTimeagen">ThePrimeagen</a>, <a href="https://www.youtube.com/@teej_dv">tjdevries</a>, and <a href="https://www.youtube.com/@typecraft_dev">typecraft</a>. They’re still burning with passion for programming. Where does that spark come from?</p>
<p>I saw them using tools like Neovim and Arch Linux (I now also use Arch Linux, by the way), advocating for proper typing, and relentlessly learning new things. And that’s when it hit me—I could be just like those junior engineers. And I could <em>start today</em>.</p>
<h2 id="phase-2-the-perceived-valley-of-despair-again">Phase 2: The Perceived Valley of Despair. Again.</h2>
<p><img src="more_dispair.png" alt="More Dispair"></p>
<p>You do not know all the things. Nobody in tech knows everything—it’s impossible to know it all. That&rsquo;s not a bug; it&rsquo;s a feature.</p>
<p>If you&rsquo;re bored with the comfort of familiarity, all you have to do to get back into Phase 2 is <em>move your feet</em>.</p>
<p>But what can you do when you&rsquo;re tired of adding yet another set of CRUD endpoints to an API?</p>
<h3 id="treat-it-like-a-video-game">Treat It Like A Video Game</h3>
<p>What do you do when you get bored of a video game but can&rsquo;t find something else to play? Try one or more of these:</p>
<ul>
<li><strong>Speedrun it.</strong></li>
<li><strong>Use a different editor.</strong></li>
<li><strong>Install mods (a.k.a. Neovim plugins).</strong></li>
<li><strong>Make your own mods.</strong></li>
<li><strong>Automate it.</strong></li>
<li><strong>Rewrite it in Rust.</strong></li>
<li><strong>Do it branchless without a single <code>if</code> statement.</strong> (Phase 1 me would have cried at the thought.)</li>
<li><strong>Become infrastructure guy™.</strong></li>
</ul>
<p>It also helps to be mindful about tiny frustrations that come up from time to time. Typing a long command in your terminal and realize you made a typo at the very start? You can either hold the left arrow key for five minutes or learn how to get to a specific part of a command more efficiently in the same amount of time.</p>
<h3 id="do-something-else-entirely">Do Something Else Entirely</h3>
<p>Are you a frontend engineer? Try backend. A backend engineer? Experiment with frontend. Full-stack? Build a video game. A game engineer? Create a text editor. For that matter, consider:</p>
<ul>
<li>Git gud at LeetCode.</li>
<li>Learn to type faster.</li>
<li>Build an embedded system.</li>
<li>Learn Assembly.</li>
<li>Start giving tech talks at work.</li>
<li>Find out what BTRFS is and how it works.</li>
<li>Experiment with writing a graphics shader.</li>
<li>Build an AI using nothing but LSTM, feed it Christmas songs in LilyPond format, and play the generated tunes at your Christmas dinner party to the annoyance of your guests.</li>
<li>Contribute to open source projects.</li>
<li>Participate in a data science competition at CERN with LHC data (I got surprisingly far).</li>
<li>Automate your house—make it track how many Chocolate Peanut Butter Oreos you have in the cupboard so you never run out again.</li>
</ul>
<p>It&rsquo;s okay to fail at half of these things. It&rsquo;s okay to only attempt a few. The only way to lose is by becoming too comfortable for too long.</p>
<h3 id="heading"><em>&ldquo;Is it just learning forever?&rdquo;</em></h3>
<p>Yes.</p>
<h3 id="heading-1"><em>&ldquo;What if I get tired of learning?&rdquo;</em></h3>
<p>If you get tired of having one foot in the known and the other in the unknown, be kind to yourself. Take a little break. A little vacation, if you will. It&rsquo;s okay. Everyone needs a break sometimes and you deserve it. Put <strong>both</strong> feet in the unknown. Go back to Phase 0. Switch to DVORAK, install Arch on your MacBook, fire up Emacs and do last year&rsquo;s Advent of Code in Rust with it after putting ChatGPT in the blocklist of your pi-hole. Embrace the suck. See how fast you can get to Phase 2 again with that setup. Do that before considering taking a vacation in the place of boredom.</p>
<p><img src="pure_unfiltered_suffering.gif" alt="Pure Unfiltered Suffering"></p>
<h2 id="the-takeaways">The Takeaways</h2>
<p>One of the greatest perks of being a knowledge worker is that our job lets us constantly learn cool new things. If you&rsquo;re an engineer—or any kind of knowledge worker—you&rsquo;ve already traveled the journey from knowing nothing to where you are now. Maybe you&rsquo;re content to coast until retirement, and that&rsquo;s perfectly fine. But for me, coasting leads to boredom, and boredom leads to burnout.</p>
<p>As knowledge workers, knowledge is value, and we share that value freely and willingly. When I submit a PR that I poured my heart into—only to have a colleague suggest an obviously better strategy that sends me back to square one—I&rsquo;m thankful every single time. I now know one more thing and that&rsquo;s valuable.</p>
<p>The goal isn’t to know everything—it’s to enjoy not knowing and keep learning anyway.</p>
<p>Even though some might see me as some kind of wizard (my monitor seems to flicker with code, windows pop in and out of existence until I miraculously raise a PR while my hands never left the keyboard), I still get overwhelmed when I look at the giant, ever-growing list of things I still want to learn. And that, in itself, makes me happy.</p>
<p><img src="happy.png" alt="Happy Not Knowing"></p>
]]></content></item></channel></rss>